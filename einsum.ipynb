{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<img src=\"attachments/einsum.png\" width='500'>\n",
    "\n",
    "<br> source: https://rockt.ai/2018/04/30/einsum"
   ],
   "id": "ee01adb3f1f1cca5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "free indices = outer loop<br>\n",
    "summation indices = inner loop"
   ],
   "id": "6a79d0073ec2cb2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T05:25:00.478759Z",
     "start_time": "2025-12-22T05:24:59.353927Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import itertools\n",
    "\n",
    "def is_same(a,b):\n",
    "    return torch.all(a==b)\n",
    "\n",
    "def all_combination(*sizes):\n",
    "    return itertools.product(*(range(s) for s in sizes)) # cartesian product"
   ],
   "id": "b139f35a18062823",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Batched Matrix Multiplication (batched Dot Product)",
   "id": "a2915de11f07efd1"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-22T05:41:12.770770Z",
     "start_time": "2025-12-22T05:41:12.763877Z"
    }
   },
   "source": [
    "B, T, C = 2,3,5\n",
    "\n",
    "Q = torch.randint(low=0, high=10, size=(B,T,C))\n",
    "K = torch.randint(low=0, high=10, size=(B,T,C))\n",
    "\n",
    "# pytorch\n",
    "y = Q @ K.transpose(-2,-1)\n",
    "\n",
    "# einsum\n",
    "y_ = torch.einsum('btc,bcT->btT', Q, K.transpose(-2,-1))\n",
    "assert is_same(y, y_)\n",
    "\n",
    "y_ = torch.einsum('btc,bTc->btT', Q, K) # implicit transpose\n",
    "assert is_same(y, y_)\n",
    "\n",
    "# free indices(outer loop): btT\n",
    "# summation indices(inner loop): c\n",
    "y_ = torch.empty((B,T,T))\n",
    "for b, tq, tk in all_combination(B,T,T): # parallel (order doesnt rly matter)\n",
    "    total = 0\n",
    "    for c in range(C): # multiplied and sum over c (as c is repeated)\n",
    "        total += Q[b,tq,c] * K[b,tk,c]\n",
    "    y_[b,tq,tk] = total\n",
    "assert is_same(y, y_)\n",
    "\n",
    "\n",
    "# extra\n",
    "# batched with head\n",
    "H = 5\n",
    "x = torch.randint(low=0, high=10, size=(B,H,T,C))\n",
    "M = torch.randint(low=0, high=10, size=(B,H,C,T))\n",
    "y = torch.einsum('bhtc, bhcT -> bhtT', x, M)\n",
    "y_ = torch.einsum('bthc, bchT -> bhtT', x.transpose(1,2), M.transpose(1,2))\n",
    "assert( y_.shape == torch.Size([B, H, T, T]) )"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# transpose",
   "id": "6906504b4c4fea8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T11:51:09.109962Z",
     "start_time": "2025-12-21T11:51:09.105723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "B,T,H,C = 2,3,4,5\n",
    "x = torch.randint(low=0, high=10, size=(B,T,H,C))\n",
    "\n",
    "y = x.transpose(1,2)\n",
    "y_ = torch.einsum('bthc->bhtc', x)\n",
    "assert is_same(y, y_)"
   ],
   "id": "2f5ce6bcfffec34e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sum",
   "id": "72b80dfc68acf597"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T15:23:45.843793Z",
     "start_time": "2025-12-21T15:23:45.816434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "B, T = 2,3\n",
    "\n",
    "x = torch.randint(low=0, high=10, size=(B,T,T))\n",
    "\n",
    "# sum over last dimension\n",
    "y = x.sum(dim=-1)\n",
    "y_ = torch.einsum('btT->bt',x)\n",
    "assert is_same(y, y_)\n",
    "\n",
    "y_ = torch.empty((B,T))\n",
    "for b, t1 in all_combination(B,T):\n",
    "    total = 0\n",
    "    for t2 in range(T):\n",
    "        total += x[b,t1,t2]\n",
    "    y_[b,t1] = total\n",
    "assert is_same(y, y_)\n",
    "\n",
    "# sum over second dim\n",
    "y = x.sum(dim=1)\n",
    "y_ = torch.einsum('btT->bT',x)\n",
    "assert is_same(y, y_)\n",
    "\n",
    "y_ = torch.empty((B,T))\n",
    "for b, t2 in all_combination(B,T):\n",
    "    total = 0\n",
    "    for t1 in range(T):\n",
    "        total += x[b,t1,t2]\n",
    "    y_[b,t2] = total\n",
    "assert is_same(y, y_)\n",
    "\n",
    "# sum over first dim\n",
    "y = x.sum(dim=0)\n",
    "y_ = torch.einsum('btT->tT',x)\n",
    "assert is_same(y, y_)\n",
    "\n",
    "# sum of all elements\n",
    "y = x.sum()\n",
    "y_ = torch.einsum('btT->',x)\n",
    "assert is_same(y, y_)"
   ],
   "id": "60061e823420c004",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Matrix Vector (element wise) Multiplication",
   "id": "b09e807591ba83e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T17:13:54.485125Z",
     "start_time": "2025-12-21T17:13:54.480082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "B, T = 2,3\n",
    "m = torch.randint(low=0, high=10, size=(B, T))\n",
    "n = torch.randint(low=0, high=10, size=[T])\n",
    "\n",
    "# sum over t\n",
    "y = torch.einsum('bt,t->b', m, n)\n",
    "y_ = (m * n).sum(dim=1)\n",
    "assert is_same(y, y_)\n",
    "\n",
    "y_ = torch.empty(B)\n",
    "for b in range(B):\n",
    "    total = 0\n",
    "    for t in range(T):\n",
    "        total += m[b, t] * n[t]\n",
    "    y_[b] = total\n",
    "assert is_same(y, y_)"
   ],
   "id": "7fae5c160de430dc",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hadamard Product (element wise multiplication)",
   "id": "1075398ac0656c9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:21:16.503725Z",
     "start_time": "2025-12-21T18:21:16.499100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "B, T, C = 2, 3, 4\n",
    "\n",
    "a = torch.randint(low=0, high=10, size=(B,T,C))\n",
    "\n",
    "y = torch.einsum('btc,btc->btc', a, a)\n",
    "y_ = a * a\n",
    "assert is_same(y, y_)\n",
    "\n",
    "y_ = torch.empty(B,T,C)\n",
    "for b, t, c in all_combination(B,T,C):\n",
    "    total = 0"
   ],
   "id": "45cddce2498f44c0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Outer Product",
   "id": "6971a8f801e1e2eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-21T18:35:28.637366Z",
     "start_time": "2025-12-21T18:35:28.632864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l = 3\n",
    "a = torch.randint(low=0, high=4, size=(l,))\n",
    "b = torch.randint(low=5, high=10, size=(l,))\n",
    "\n",
    "y = torch.einsum('i,j->ij', a, b)\n",
    "y_ = a.unsqueeze(1) * b.unsqueeze(0) # [i,1] * [1,j] -> [i,j]\n",
    "assert is_same(y, y_)\n",
    "\n",
    "# free indices: ij\n",
    "# summation indices: None\n",
    "y_ = torch.empty(l,l)\n",
    "for i, j in all_combination(l, l):\n",
    "    y_[i, j] = a[i] * b[j]\n",
    "assert is_same(y, y_)"
   ],
   "id": "45454d3bc20e9058",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# tensor contraction (IMPORTANT)\n",
    "\n",
    "most tensor operations are tensor contractions (observe the previous operations)"
   ],
   "id": "5774c5558b7e5e1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T05:42:24.720393Z",
     "start_time": "2025-12-22T05:42:19.217168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "U, V = 3, 5\n",
    "a,b,c,d,e = 2,7,11,13,17\n",
    "\n",
    "x1 = torch.randint(low=0, high=4,size=(a,U,V,b))\n",
    "x2 = torch.randint(low=5, high=10, size=(c,d,U,e,V))\n",
    "\n",
    "y = torch.einsum('aUVb,cdUeV->abcde', x1, x2)\n",
    "\n",
    "# free indices: abcde\n",
    "# summation indices: U, V\n",
    "y_ = torch.empty(a,b,c,d,e)\n",
    "for ai, bi, ci, di, ei in all_combination(a, b, c, d, e):\n",
    "    patch_total = 0\n",
    "    for u, v in all_combination(U, V):\n",
    "        patch_total += x1[ai,u,v,bi] * x2[ci,di,u,ei,v]\n",
    "    y_[ai,bi,ci,di,ei] = patch_total\n",
    "assert is_same(y, y_)\n",
    "\n",
    "\n",
    "# batch matrix multiplication is a special case of tensor contraction\n",
    "B, T, C, D = 2, 3, 4, 7\n",
    "x = torch.randint(low=0, high=10, size=(B,T,C))\n",
    "M = torch.randint(low=0, high=10, size=(B,C,D))\n",
    "\n",
    "# free indices: btd (because b is in both tensors, we dont repeat it, which is a special case)\n",
    "# summation indices: c\n",
    "y_ = torch.einsum('btc,bcd->btd', x, M)\n",
    "assert( y_.shape == torch.Size([B, T, D]) )\n",
    "\n",
    "# if b is diff\n",
    "B1, B2 = 2, 3\n",
    "x = torch.randint(low=0, high=10, size=(B1,T,C))\n",
    "M = torch.randint(low=0, high=10, size=(B2,C,D))\n",
    "y_ = torch.einsum('btc,Bcd->bBtd', x, M)\n",
    "assert( y_.shape == torch.Size([B1,B2, T, D]) )\n",
    "\n",
    "# batched with head\n",
    "H = 5\n",
    "x = torch.randint(low=0, high=10, size=(B,H,T,C))\n",
    "M = torch.randint(low=0, high=10, size=(B,H,C,D))\n",
    "y_ = torch.einsum('bhtc, bhcd -> bhtd', x, M)\n",
    "assert( y_.shape == torch.Size([B,H, T, D]) )\n",
    "\n",
    "# this is also why we need a different T in the einsum, as it should be a different dimension in the output\n",
    "x = torch.randint(low=0, high=10, size=(B,H,T,C))\n",
    "M = torch.randint(low=0, high=10, size=(B,H,C,T))\n",
    "y_ = torch.einsum('bhtc, bhcT -> bhtT', x, M)\n",
    "assert( y_.shape == torch.Size([B, H, T, T]) )"
   ],
   "id": "258479c024c92a7b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bilinear Transformation",
   "id": "6982f5696a3d28ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T05:54:25.907696Z",
     "start_time": "2025-12-22T05:54:25.904260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "i,j,K,L = 2,3,5,7\n",
    "\n",
    "x1 = torch.randn(i, K)\n",
    "x2 = torch.randn(j, K, L)\n",
    "x3 = torch.randn(i, L)\n",
    "\n",
    "# free indices: ij\n",
    "# summation indices: KL\n",
    "y = torch.einsum('iK, jKL, iL -> ij', x1, x2, x3)\n",
    "\n",
    "# iK, jKL -> ijL (tensor contraction)\n",
    "# ijL, iL -> ij (batched matrix vector)\n",
    "y_ = torch.einsum('iK, jKL -> ijL', x1, x2)\n",
    "y_ = torch.einsum('ijL, iL -> ij', y_, x3)\n",
    "assert is_same(y, y_)"
   ],
   "id": "8805f0112c7565dd",
   "outputs": [],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
